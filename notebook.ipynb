{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7016bb66-9fdc-47f4-870f-51e25d5cb10a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1806,
    "lastExecutedAt": 1743473599622,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, when, mean, count, isnan, regexp_replace\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean, count, isnan, regexp_replace\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fba60f-55fe-4c4d-be6e-cb047be65523",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3092,
    "lastExecutedAt": 1743473672957,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "spark = SparkSession.builder.appName(\"MerchSalesProcessing\").getOrCreate()",
    "outputsMetadata": {
     "0": {
      "height": 101,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/01 02:14:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MerchSalesProcessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d411c7c-6cdd-433c-a1e3-8ced61631def",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4422,
    "lastExecutedAt": 1743473740717,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data = spark.read.csv('merch_sales_dataset.csv',header=True,inferSchema=True)"
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('merch_sales_dataset.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b285d280-8706-407d-93dd-c3aba29cee50",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 423,
    "lastExecutedAt": 1743473769097,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data.show(5,0)",
    "outputsMetadata": {
     "0": {
      "height": 525,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+----------------------------------------------------+\n",
      "|Order ID|Order Date|Product ID|Product Category|Buyer Gender|Buyer Age|Order Location|International Shipping|Sales Price|Shipping Charges|Sales per Unit|Quantity|Total Sales|Rating|Review                                              |\n",
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+----------------------------------------------------+\n",
      "|189440  |7/21/2024 |BF1543    |Clothing        |Male        |30       |New Jersey    |No                    |100        |0               |100           |1       |100        |4     |The delivery team handled the product with care.    |\n",
      "|187385  |7/20/2024 |BF1543    |Clothing        |Male        |32       |Las Vegas     |No                    |100        |0               |100           |1       |100        |3     |Had slight delays but the product was in good shape.|\n",
      "|181844  |7/21/2024 |BF1544    |Other           |Female      |26       |Cardiff       |Yes                   |9          |40              |49            |1       |49         |2     |Waste of Money.                                     |\n",
      "|197934  |8/19/2024 |BF1544    |Other           |Male        |28       |Pittsburgh    |No                    |9          |0               |9             |2       |18         |3     |Had slight delays but the product was in good shape.|\n",
      "|122470  |1/6/2024  |BF1545    |Other           |Female      |19       |Miami         |No                    |10         |0               |10            |3       |30         |5     |Lack of delivery delays is greatly appreciated.     |\n",
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+----------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b52f78c-b47e-4fe8-a0ed-c4f6e38742ab",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1002,
    "lastExecutedAt": 1743473842936,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Check for missing values\nmissing_counts = data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns])\nmissing_counts.show()",
    "outputsMetadata": {
     "0": {
      "height": 248,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+------+\n",
      "|Order ID|Order Date|Product ID|Product Category|Buyer Gender|Buyer Age|Order Location|International Shipping|Sales Price|Shipping Charges|Sales per Unit|Quantity|Total Sales|Rating|Review|\n",
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+------+\n",
      "|       0|         0|         0|               0|           0|        0|             0|                     0|          0|               0|             0|       0|          0|     0|     0|\n",
      "+--------+----------+----------+----------------+------------+---------+--------------+----------------------+-----------+----------------+--------------+--------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_counts = data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88f21f0-fa44-47ea-998f-4ccc8f714cfd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1743473963910,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Drop rows in Total Sales and Review columns with NULL values\ndata = data.dropna(subset=[\"Total Sales\", \"Review\"])"
   },
   "outputs": [],
   "source": [
    "# Drop rows in Total Sales and Review columns with NULL values\n",
    "data = data.dropna(subset=[\"Total Sales\", \"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d61d2a-b6c3-4349-9f6e-ecfa94103b57",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1688,
    "lastExecutedAt": 1743474046655,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Fill missing numerical values with the column mean\nnumeric_cols = [\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Total Sales\", \"Rating\", \"Buyer Age\"]\nfor col_name in numeric_cols:\n    mean_value = data.select(mean(col(col_name))).collect()[0][0]\n    data = data.fillna({col_name: mean_value})"
   },
   "outputs": [],
   "source": [
    "# Fill missing numerical values with the column mean\n",
    "numeric_cols = [\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Total Sales\", \"Rating\", \"Buyer Age\"]\n",
    "for col_name in numeric_cols:\n",
    "    mean_value = data.select(mean(col(col_name))).collect()[0][0]\n",
    "    data = data.fillna({col_name: mean_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc23feb-48a9-478c-a570-a46d4212d999",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1743474172114,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Fill missing categorical values with \"Unknown\"\ncategorical_cols = [\"Product Category\", \"Buyer Gender\", \"Order Location\", \"International Shipping\"]\ndata = data.fillna({col_name: \"Unknown\" for col_name in categorical_cols})"
   },
   "outputs": [],
   "source": [
    "# Fill missing categorical values with \"Unknown\"\n",
    "categorical_cols = [\"Product Category\", \"Buyer Gender\", \"Order Location\", \"International Shipping\"]\n",
    "data = data.fillna({col_name: \"Unknown\" for col_name in categorical_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfae846-cf42-458e-b081-60c4a14339e8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1743474411891,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data = data.dropDuplicates()"
   },
   "outputs": [],
   "source": [
    "data = data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba14ba5-1b10-4fbe-94fc-a711d76f0f52",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3117,
    "lastExecutedAt": 1743474519058,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.sql.functions import stddev\n\n# Define function to remove outliers\ndef remove_outliers(data, col_name):\n    stats = data.select(mean(col(col_name)).alias(\"mean\"), stddev(col(col_name)).alias(\"std\")).collect()[0]\n    mean_val, std_val = stats[\"mean\"], stats[\"std\"]\n    return data.filter((col(col_name) > mean_val - 3 * std_val) & (col(col_name) < mean_val + 3 * std_val))\n\n# Apply to numeric columns\nfor col_name in [\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Total Sales\"]:\n    data = remove_outliers(data, col_name)"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "# Define function to remove outliers\n",
    "def remove_outliers(data, col_name):\n",
    "    stats = data.select(mean(col(col_name)).alias(\"mean\"), stddev(col(col_name)).alias(\"std\")).collect()[0]\n",
    "    mean_val, std_val = stats[\"mean\"], stats[\"std\"]\n",
    "    return data.filter((col(col_name) > mean_val - 3 * std_val) & (col(col_name) < mean_val + 3 * std_val))\n",
    "\n",
    "# Apply to numeric columns\n",
    "for col_name in [\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Total Sales\"]:\n",
    "    data = remove_outliers(data, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40d680f2-c59c-4dac-8e89-661a9e24a9bf",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 580,
    "lastExecutedAt": 1743475010372,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "if \"feature_raw\" in data.columns:\n    data = data.drop(\"feature_raw\")\n\n#Standardization for numeric columns\nassembler = VectorAssembler(inputCols=[\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Buyer Age\"], outputCol=\"feature_raw\")\ndata = assembler.transform(data)\n\nscaler = StandardScaler(inputCol=\"feature_raw\", outputCol=\"feature\", withStd=True, withMean=True)\ndata = scaler.fit(data).transform(data)"
   },
   "outputs": [],
   "source": [
    "if \"feature_raw\" in data.columns:\n",
    "    data = data.drop(\"feature_raw\")\n",
    "\n",
    "#Standardization for numeric columns\n",
    "assembler = VectorAssembler(inputCols=[\"Sales Price\", \"Shipping Charges\", \"Sales per Unit\", \"Quantity\", \"Buyer Age\"], outputCol=\"feature_raw\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"feature_raw\", outputCol=\"feature\", withStd=True, withMean=True)\n",
    "data = scaler.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d98933d-1fd3-430f-9572-664e6bcbd326",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1743475121018,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data_regression = data.select(\"feature\", \"Total Sales\")"
   },
   "outputs": [],
   "source": [
    "data_regression = data.select(\"feature\", \"Total Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaeb962d-27f9-42a0-8187-48d5ae9ce0e3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1957,
    "lastExecutedAt": 1743475313360,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Split into train and test\ntrain_reg, test_reg = data_regression.randomSplit([0.8, 0.2], seed=42)\n\n# Train Linear Regression Model\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol=\"feature\", labelCol=\"Total Sales\")\nmodel_reg = lr.fit(train_reg)",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/01 02:41:52 WARN Instrumentation: [d1d32b5c] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/04/01 02:41:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "train_reg, test_reg = data_regression.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train Linear Regression Model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol=\"feature\", labelCol=\"Total Sales\")\n",
    "model_reg = lr.fit(train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c158de8-9aa6-4db9-b197-2a3ea886d9c6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 527,
    "lastExecutedAt": 1743475388113,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Evaluate Regression Model\npredictions_reg = model_reg.transform(test_reg)\npredictions_reg.select(\"Total Sales\", \"prediction\").show(5)",
    "outputsMetadata": {
     "0": {
      "height": 248,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|Total Sales|         prediction|\n",
      "+-----------+-------------------+\n",
      "|          9|-13.769508030241582|\n",
      "|          9|-13.769508030241582|\n",
      "|          9|-13.769508030241582|\n",
      "|          9|-13.769508030241582|\n",
      "|          9|-13.721150350667173|\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Regression Model\n",
    "predictions_reg = model_reg.transform(test_reg)\n",
    "predictions_reg.select(\"Total Sales\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a89cb2-782c-48fc-8a7f-fc8807967c85",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 714,
    "lastExecutedAt": 1743475611620,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Preparing for classification\n# Convert text reviews into numerical labels using StringIndexer\nindexer = StringIndexer(inputCol=\"Review\", outputCol=\"label\")\ndata_classification = indexer.fit(data).transform(data).select(\"features\", \"label\")",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "#Preparing for classification\n",
    "# Convert text reviews into numerical labels using StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Review\", outputCol=\"label\")\n",
    "data_classification = indexer.fit(data).transform(data).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881b169e-db93-4cf9-aa52-017b1db4e843",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7058,
    "lastExecutedAt": 1743475712637,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Split into train and test\ntrain_cls, test_cls = data_classification.randomSplit([0.8, 0.2], seed=42)\n\n# Train a Classification Model (Logistic Regression)\nfrom pyspark.ml.classification import LogisticRegression\nlr_cls = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\nmodel_cls = lr_cls.fit(train_cls)",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_cls, test_cls = data_classification.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train a Classification Model (Logistic Regression)\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr_cls = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model_cls = lr_cls.fit(train_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037eb3b2-2be4-4bc5-9cf9-62edacd51a4d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 511,
    "lastExecutedAt": 1743475792115,
    "lastExecutedByKernel": "9d5f1863-1bf0-4f25-a59b-c812926796c5",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Evaluate Classification Model\npredictions_cls = model_cls.transform(test_cls)\npredictions_cls.select(\"label\", \"prediction\").show(5)",
    "outputsMetadata": {
     "0": {
      "height": 248,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  2.0|       7.0|\n",
      "|  6.0|       7.0|\n",
      "|  8.0|       7.0|\n",
      "| 24.0|       7.0|\n",
      "|  4.0|       7.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Classification Model\n",
    "predictions_cls = model_cls.transform(test_cls)\n",
    "predictions_cls.select(\"label\", \"prediction\").show(5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
